{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUEHz3HYH55x"
      },
      "source": [
        "# Multi-scale Dilation with Residual Fused Attention for Low Dose CT Noise Artifact (MD-RFA)\n",
        "\n",
        "This notebook has three sections:\n",
        "* **Section 1:** Data Processing of DICOM files.\n",
        "* **Section 2:** Building MD-RFA model architecture.\n",
        "* **Section 3:** Training Network and Evaluating.\n",
        "\n",
        "Let's begin with installing any necesssary libraries and importing our libraries for preprocessing and training of network.\n",
        "\n",
        "I have acquired my data from my supervisor and can share it upon request, however for now I will import my datasets to the Jupyter working directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bXrhVHGRLu7U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a9b2925-737d-44d6-d6e5-1b98eb1a5a51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EBwniaT0MAOP"
      },
      "outputs": [],
      "source": [
        "!mkdir data/\n",
        "!mkdir data/processed\n",
        "!mkdir model\n",
        "!mkdir model/weights/\n",
        "!cp -r /gdrive/MyDrive/datasets/ datasets/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDVRGWyxLV1S"
      },
      "outputs": [],
      "source": [
        "!pip install pydicom\n",
        "!pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1rkJy52TH24K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3647203-b14e-4321-9d22-d2ca0785f533"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np # linear algebra\n",
        "import pydicom as dicom\n",
        "import os\n",
        "import gc\n",
        "import scipy.ndimage\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import h5py\n",
        "\n",
        "# Model Components\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, Multiply, Conv2DTranspose\n",
        "from tensorflow.keras.layers import Activation, AveragePooling2D\n",
        "from tensorflow.keras.layers import Add, concatenate, Input, subtract\n",
        "from tensorflow.keras.layers import BatchNormalization as BN\n",
        "\n",
        "# For model training and testing\n",
        "import multiprocessing\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras import losses\n",
        "from keras.losses import MeanSquaredError\n",
        "import math\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.efficientnet import EfficientNetB2\n",
        "from tensorflow.keras.applications.densenet import DenseNet121\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
        "from keras.models import Model\n",
        "from skimage.metrics import structural_similarity as compare_ssim\n",
        "\n",
        "SEED= 42\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Section 1:** Data Processing of DICOM files"
      ],
      "metadata": {
        "id": "_Xdofctbt2NW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lDGAlBiOP37"
      },
      "source": [
        "* Let's build our functions to process the DICOM files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0SDpNtoiOY5y"
      },
      "outputs": [],
      "source": [
        "# Load the scans in given folder path\n",
        "def load_scan(path):\n",
        "    slices = [dicom.read_file(path + '/' + s) for s in os.listdir(path)]\n",
        "    slices.sort(key = lambda x: float(x.ImagePositionPatient[2]))\n",
        "    try:\n",
        "        #distance between slices, finds slice tkickness if not availabe\n",
        "        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n",
        "    except:\n",
        "        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n",
        "        \n",
        "    for s in slices:\n",
        "        s.SliceThickness = slice_thickness\n",
        "        \n",
        "    return slices\n",
        "\n",
        "# Taking Housenfield Unit into consideration\n",
        "def get_pixels_hu(slices):\n",
        "    # read the dicom images, find HU numbers (padding, intercept, rescale), and make a 4-D array, \n",
        "    # HU - Hounsfield Unit (HU): measure of radiodensity\n",
        "\n",
        "    image = np.stack([s.pixel_array for s in slices])\n",
        "    # Convert to int16 (from sometimes int16), \n",
        "    # should be possible as values should always be low enough (<32k)\n",
        "    image = image.astype(np.int16)\n",
        "\n",
        "    # Set outside-of-scan pixels to 0\n",
        "    # The intercept is usually -1024, so air is approximately 0\n",
        "    try:\n",
        "        padding = slices[0].PixelPaddingValue\n",
        "    except:\n",
        "        padding = 0\n",
        "    \n",
        "    image[image == padding] = 0\n",
        "    \n",
        "    # Convert to Hounsfield units (HU)\n",
        "    for slice_number in range(len(slices)):\n",
        "        \n",
        "        intercept = slices[slice_number].RescaleIntercept\n",
        "        slope = slices[slice_number].RescaleSlope\n",
        "        \n",
        "        if slope != 1:\n",
        "            image[slice_number] = slope * image[slice_number].astype(np.float64)\n",
        "            image[slice_number] = image[slice_number].astype(np.int16)\n",
        "            \n",
        "        image[slice_number] += np.int16(intercept)\n",
        "        \n",
        "    return np.array(image, dtype=np.int16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ri4-C0YOoGn"
      },
      "source": [
        "* Next we want to extract patches for faster training and reduces computation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gdKoF5nMOupP"
      },
      "outputs": [],
      "source": [
        "# This function extracts patches from the larger image\n",
        "def extract_patches(image, patch_size=40,stride=20):\n",
        "    \n",
        "    images_num,h,w = image.shape\n",
        "    out = np.empty((0,patch_size,patch_size))\n",
        "    sz = image.itemsize\n",
        "    shape = ((h-patch_size)//stride+1, (w-patch_size)//stride+1, patch_size,patch_size)\n",
        "    strides = sz*np.array([w*stride,stride,w,1])\n",
        "\n",
        "    for d in range (0,images_num):\n",
        "        patches=np.lib.stride_tricks.as_strided(image[d,:,:], shape=shape, strides=strides)\n",
        "        blocks=patches.reshape(-1,patch_size,patch_size)\n",
        "        out=np.concatenate((out,blocks[:,:,:]))\n",
        "        #print(d)\n",
        "    \n",
        "    return out[:,:,:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RRsbNWTO0G0"
      },
      "source": [
        "* Last we want to save our data in `.h5` format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PkFNh7a8O53w"
      },
      "outputs": [],
      "source": [
        "def write_hdf5(data,labels, output_filename):\n",
        "    \"\"\"\n",
        "    This function is used to save image data and its label(s) to hdf5 file.\n",
        "    output_file.h5,contain data and label\n",
        "    \"\"\"\n",
        "\n",
        "    with h5py.File(output_filename, 'w') as h:\n",
        "        h.create_dataset('data', data=data, shape=data.shape)        \n",
        "        h.create_dataset('label', data=labels, shape=labels.shape)\n",
        "        h.close()\n",
        " \n",
        "\n",
        "def read_hdf5(file):\n",
        "    with h5py.File(file, 'r') as hf:\n",
        "        data = np.array(hf.get('data'))\n",
        "        labels = np.array(hf.get('label'))\n",
        "   \n",
        "        return data,labels "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3FgTiXWPC6W"
      },
      "source": [
        "* Here the required folders and file names are saved into an array for automating the data processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sWrjBxKKPg_I"
      },
      "outputs": [],
      "source": [
        "# Setting paths for all data sets and for saving files\n",
        "low_dose_files=['datasets/Thoracic/Copies/Low Dose', 'datasets/Piglet/Paired/Low', \n",
        "                  'datasets/Head - TCIA - Subject N012/Low Dose Images','datasets/Chest - TCIA - Subject C002/Low Dose Images',\n",
        "                  'datasets/Abdomen - TCIA - Subject L058/Low Dose Images']\n",
        "\n",
        "full_dose_files=['datasets/Thoracic/Copies/High Dose', 'datasets/Piglet/Paired/High', \n",
        "                  'datasets/Head - TCIA - Subject N012/Full Dose Images','datasets/Chest - TCIA - Subject C002/Full Dose Images',\n",
        "                  'datasets/Abdomen - TCIA - Subject L058/Full Dose Images']\n",
        "\n",
        "patch_size = '32_32'\n",
        "dataset_type = ['thoracic', 'piglet', 'head_N012', 'chest_C002', 'abdomen_L058']\n",
        "train_data_path = ['data/processed/train_{}_{}_dicom_0.h5'.format(patch_size, type_) for type_ in dataset_type]\n",
        "test_data_path = ['data/processed/test_{}_{}_dicom_0.h5'.format(patch_size, type_) for type_ in dataset_type]\n",
        "\n",
        "                  ###############################################\n",
        "folder = ['Thoracic', 'Piglet', 'Head - TCIA - Subject N012', 'Chest - TCIA - Subject C002', 'Abdomen - TCIA - Subject L058']\n",
        "train_data_files = ['datasets/{}/train_{}_{}_dicom_0.h5'.format(folder[i], patch_size, dataset_type[i]) for i in range(len(folder))]\n",
        "test_data_files = ['datasets/{}/test_{}_{}_dicom_0.h5'.format(folder[i], patch_size, dataset_type[i]) for i in range(len(folder))]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5McpZJ5PPouM"
      },
      "source": [
        "We then do the following:\n",
        "* Load dataset\n",
        "* Process DICOM data in terms of HU and convert to numpy array.\n",
        "* Split data to 70% train and 30% test.\n",
        "* Extract patches for patch training."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The below function automates the process of saving pocessed data to your google drive directory.\n",
        "* It also saves to local directory under ``data/processed``"
      ],
      "metadata": {
        "id": "JLLQYAjfSgX-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EhvhfqNaPnnp"
      },
      "outputs": [],
      "source": [
        "drive_file = ['Thoracic', 'Piglet', 'Head - TCIA - Subject N012', 'Chest - TCIA - Subject C002', 'Abdomen - TCIA - Subject L058']\n",
        "def process_data(path_low, path_high, train_data_path, test_data_path, patch_size, drive_file):\n",
        "  for i in range(len(path_high)):\n",
        "    # Loading dicom files from Piglet dataset \n",
        "    slices_data_train = load_scan(path_low[i])\n",
        "    slices_labels_train = load_scan(path_high[i])\n",
        "\n",
        "    #callibrating in terms of HU\n",
        "    data = get_pixels_hu(slices_data_train)+1024 \n",
        "    labels = get_pixels_hu(slices_labels_train)+1024\n",
        "\n",
        "    # Dividing into train (70%) and test(30%) datasets \n",
        "    n = len(data)*7//10\n",
        "    data_train ,data_test = data[:n],data[n:]\n",
        "    labels_train,labels_test = labels[:n],labels[n:]\n",
        "\n",
        "    # Extract patches from data (low) and label (high), patch size and stride of 32\n",
        "    data_patch=extract_patches(data_train,patch_size=patch_size,stride=patch_size)\n",
        "    labels_patch=extract_patches(labels_train,patch_size=patch_size,stride=patch_size)\n",
        "\n",
        "    # write in h5 files (piglet)\n",
        "    write_hdf5(data_patch,labels_patch, train_data_path[i])\n",
        "    write_hdf5(data_test,labels_test,test_data_path[i])\n",
        "\n",
        "    # cmd1 = 'cp {} /gdrive/MyDrive/datasets/{}'.format(train_data_path[i], drive_file[i])\n",
        "    # cmd2 = 'cp {} /gdrive/MyDrive/datasets/{}'.format(test_data_path[i], drive_file[i])\n",
        "    # os.system(cmd1)\n",
        "    # os.system(cmd2)\n",
        "\n",
        "process_data(low_dose_files, full_dose_files, train_data_path, test_data_path, 32, drive_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J51MlCqQ13H"
      },
      "source": [
        "## **Section 2:** Building MD-RFA Architecture\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the Boosting Module Group (BMG)\n",
        "* The spatial-attention module is developed as a seperate function which accepts a feature map as it's input\n",
        "* The channel-attention module is developed as a seperate function which accepts a feature map as it's input\n",
        "* Using both channel- and spatial-attention modules a parallel integration with skip connections with each modules are done to develop the Boosting Attention Fusion Block (BAFB)\n",
        "* Once the BAFB is developed a series connection of 4 BAFB are used with one skip connection to build the BMG"
      ],
      "metadata": {
        "id": "HEbgm5wgUirj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xOr7ak-eT625"
      },
      "outputs": [],
      "source": [
        "# Spatial Attention\n",
        "def SA(feat_map):\n",
        "    conv1 = Conv2D(64, (1,1), strides=1, padding='valid')(feat_map)\n",
        "    conv2 = Conv2D(64, (1,1), strides=1, padding='valid')(feat_map)\n",
        "    conv3 = Conv2D(64, (3,3), strides=1, activation='relu', padding='same')(feat_map)\n",
        "    conv3 = Conv2D(64, (3,3), strides=1, padding='same')(conv3)\n",
        "    \n",
        "    conv4 = Multiply()([conv1, conv2])\n",
        "    conv4_softmax = tf.keras.activations.softmax(conv4)\n",
        "    conv5 = Multiply()([conv3, conv4_softmax])\n",
        "    conv5 = Conv2D(64, (1,1), strides=1, padding='valid')(conv5)\n",
        "    \n",
        "    sa_feat_map = Add()([feat_map, conv5]) # Original\n",
        "    \n",
        "    return sa_feat_map\n",
        "\n",
        "# Channel Attention \n",
        "def CA(feat_map):\n",
        "    conv1 = AveragePooling2D(pool_size=(1,1), strides=1, padding='valid')(feat_map)  \n",
        "    conv2 = Conv2D(64, (1,1), strides=1, activation='relu', padding='valid')(conv1)  \n",
        "    conv3 = Conv2D(64, (1,1), strides=1, activation='sigmoid',padding='valid')(conv2)\n",
        "    \n",
        "    ca_feat_map = Multiply()([feat_map, conv3])\n",
        "    \n",
        "    return ca_feat_map\n",
        "\n",
        "# BAFB -- four for each BMG in the denoiser\n",
        "def BAFB(input_bafb):\n",
        "    fcr1 = Conv2D(64, (1,1), strides=1, activation='relu', padding='valid')(input_bafb)\n",
        "    \n",
        "    fsa1 = SA(fcr1)\n",
        "    fes_up = Add()([fsa1,fcr1])\n",
        "    \n",
        "    fca1 = CA(fcr1)\n",
        "    fes_down = Add()([fca1, fcr1])\n",
        "    \n",
        "    fca2 = CA(fes_up)\n",
        "    fsa2 = SA(fes_down)\n",
        "    \n",
        "    fcr2=concatenate([fca2, fes_up, fes_down, fsa2],axis=3)\n",
        "    fcr2=Conv2D(1, (1,1), strides=1, activation='relu', padding='valid')(fcr2) \n",
        "    \n",
        "    fc=concatenate([fcr1, fcr2],axis=3)\n",
        "    fc=Conv2D(1, (1,1), strides=1, padding='valid')(fc) \n",
        "    \n",
        "    return fc\n",
        "\n",
        "# Boosting Module Groups (BMG)\n",
        "def BMG(bmg_input):\n",
        "    bafb1 = BAFB(bmg_input)\n",
        "    bafb2 = BAFB(bafb1)\n",
        "    bafb3 = BAFB(bafb2)\n",
        "    bafbn = BAFB(bafb3)   \n",
        "    fg = Add()([bmg_input,bafbn])\n",
        "    return fg"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Fused Attention Modules with Dilated Residual Learning (FAM-DRL)\n",
        "* Below is the model architecture for the benchmark model that achieved state-of-the-arts results.\n",
        "* This model is used to compare performance with the MD-RFA model."
      ],
      "metadata": {
        "id": "SE4IuG5WVfDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fam_drl():\n",
        "    inputs = (None, None, 1)\n",
        "    inputs=Input(shape=inputs)\n",
        "    # 1) Preconvolutional module (number of filters in each layer = 1)\n",
        "    f1sf = Conv2D(64, (3,3), dilation_rate=(2,2), padding='same')(inputs)\n",
        "    f1sf = BN()(f1sf)\n",
        "    f1sf = Activation('relu')(f1sf)\n",
        "    \n",
        "    f2sf = Conv2D(64, (3,3), dilation_rate=(2,2),padding='same')(f1sf)\n",
        "    f2sf = BN()(f2sf)\n",
        "    f2sf = Activation('relu')(f2sf)\n",
        "    \n",
        "    f3sf = Conv2D(64, (3,3), dilation_rate=(2,2),padding='same')(f2sf)\n",
        "    f3sf = BN()(f3sf)\n",
        "    f3sf = Activation('relu')(f3sf)\n",
        "    \n",
        "    \n",
        "    # 2) Three BMGs with 3 BAFBs each\n",
        "    bmg1= BMG(f3sf)\n",
        "    bmg2= BMG(bmg1)\n",
        "    bmg3 = BMG(bmg2)\n",
        "    \n",
        "    f4sf = Add()([f3sf, bmg3])\n",
        "    \n",
        "    # 3) Post convolution Fpost = R3postC(R2postC( R1postC(bmg2)+F2sf ) + F1sf )\n",
        "    dconv3 = Conv2D(64, (3,3), dilation_rate=(2,2),padding='same')(f4sf)\n",
        "    dconv3 = BN()(dconv3)\n",
        "    dconv3 = Activation('relu')(dconv3)\n",
        "    \n",
        "    dconv2 = Conv2D(64, (3,3), dilation_rate=(2,2),padding='same')(dconv3)  \n",
        "    dconv2 = BN()(dconv2)\n",
        "    dconv2 = Activation('relu')(dconv2)\n",
        "    \n",
        "    dconv1 = Add()([f2sf, dconv2])  # Symmetric skip connection (SSC)\n",
        "    # skip1 = concatenate([dconv2, f1sf], axis=3)\n",
        "    dconv1 = Conv2D(64, (3,3), dilation_rate=(2,2),padding='same')(dconv1)  \n",
        "    dconv1 = BN()(dconv1)\n",
        "    dconv1 = Activation('relu')(dconv1)\n",
        "    \n",
        "    # 4) Reconstruction Layer\n",
        "    out = Add()([inputs, dconv1])\n",
        "    out= Conv2DTranspose(3, (3,3), dilation_rate=(2,2),padding='same')(out) \n",
        "\n",
        "    resnet=Model(inputs=[inputs], outputs=[out, out, out]) \n",
        "    return resnet"
      ],
      "metadata": {
        "id": "VjOrqXkHVdhG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Model summary"
      ],
      "metadata": {
        "id": "rzeRO2yfWKac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = fam_drl()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "dUpCo-A8vBTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Multi-scale Dilation with Residual Fused Attention (MD-RFA)\n",
        "\n",
        "####Main model components\n",
        "* **Multi-scale feature mapping:** Using dirrent dilation rates with the convolution layer a hierarchy of noise feature maps are extracted.\n",
        "* **Boosting Module Groups:** Utilizing the BMG, the model learns the long-range dependencies of the LDCT image.\n",
        "* **Reconstruction Layers:** Reconstructs the learned noise feature map to remove from the LDCT image."
      ],
      "metadata": {
        "id": "s9fFrwRXvFrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dilated_conv_block(dc_input, num_filters, kernel_size, dilation_rate, padding='same', activation='relu'):\n",
        "    x = Conv2D(num_filters, kernel_size, dilation_rate=dilation_rate, padding=padding, activation=activation)(dc_input)\n",
        "    x = Conv2D(num_filters, kernel_size, dilation_rate=dilation_rate, padding=padding, activation=activation)(x)\n",
        "    return x\n",
        "\n",
        "def md_rfa():\n",
        "    inputs = (None, None, 1)\n",
        "    inputs=Input(shape=inputs)\n",
        "\n",
        "    fm1 = dilated_conv_block(inputs, 32, 3, 1)\n",
        "    fm2 = dilated_conv_block(inputs, 32, 3, 2)\n",
        "    fm3 = dilated_conv_block(inputs, 32, 3, 4)\n",
        "    fm4 = concatenate([fm1, fm2, fm3], axis=-1)\n",
        "    fm_out = Conv2D(64, 3, dilation_rate=2, padding='same', activation='relu')(fm4)\n",
        "\n",
        "    bmg1= BMG(fm_out)\n",
        "    bmg2= BMG(bmg1)\n",
        "    bmg3 = BMG(bmg2)\n",
        "\n",
        "    s1 = Add()([fm_out, bmg3])\n",
        "\n",
        "    decoder1 = Conv2D(64, 3, dilation_rate=2, padding='same', activation='relu')(s1)\n",
        "    decoder2 = Conv2D(64, 3, dilation_rate=2, padding='same', activation='relu')(decoder1)\n",
        "    decoder3 = Conv2D(3, 3, dilation_rate=2, padding='same')(decoder2)\n",
        "\n",
        "    out = subtract([inputs, decoder3])\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[out, out, out])\n",
        "    return model"
      ],
      "metadata": {
        "id": "LFpGVipBvCLF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = md_rfa()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "T1PA71_WvVu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Section 3:** Training Network and Evaluating\n",
        "\n",
        "Three steps for training the network:\\\n",
        "1) Initializing the feature extraction models and loss functions\\\n",
        "2) Preparing training data\\\n",
        "3) Training model\n",
        "\n",
        "Two steps for eveluating:\\\n",
        "1) Prepaing test data\\\n",
        "2) Testing model"
      ],
      "metadata": {
        "id": "7Pv3UHeIYcWa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AafsoI4HV7bL"
      },
      "source": [
        "### Feature Extraction and model loss functions\n",
        "#### Train Model and Validate\n",
        "To do this we do the following:\n",
        "* Develop and Initialize the Loss functions for training\n",
        "* Load data and prepare it.\n",
        "* Train the network using tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Xiha0Ufp5sH7"
      },
      "outputs": [],
      "source": [
        "# Strutural Dissimilarity Loss function\n",
        "def dssim_loss(y_true, y_pred):\n",
        "    ssim = tf.image.ssim(y_true, y_pred, 1.0)\n",
        "    return (1.0-ssim)/2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Feature Extraction with ResNet50V2"
      ],
      "metadata": {
        "id": "72poa2FRxk-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet50V2Model(object):\n",
        "    def __init__(self, image_shape=(None, None, 3)):\n",
        "        self.image_shape = image_shape\n",
        "        self.resnet = ResNet50V2(include_top=False, weights='imagenet', input_shape=self.image_shape)\n",
        "        self.selectedLayers = ['conv1_conv','conv2_block2_out','conv3_block3_out']\n",
        "        self.selectedOutputs = [self.resnet.get_layer(i).output for i in self.selectedLayers]\n",
        "        self.loss_model = Model(inputs=self.resnet.input, outputs=self.selectedOutputs)\n",
        "        self.loss_model.trainable = False\n",
        "        self.mse = MeanSquaredError()\n",
        "\n",
        "    def perceptual_loss(self, y_true, y_pred):\n",
        "        loss_value = 0\n",
        "        for i in range(0,3):\n",
        "            loss_value += self.mse(self.loss_model((y_true*2.0)-1.0)[i], self.loss_model((y_pred*2.0)-1.0)[i])\n",
        "        return loss_value"
      ],
      "metadata": {
        "id": "jdRf2Swlxe9_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Metrics used to measure training loss"
      ],
      "metadata": {
        "id": "Fbp47DFwtJmp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "yh7TJL1-6eoS"
      },
      "outputs": [],
      "source": [
        "# Metrics\n",
        "def psnr_loss(y_true, y_pred):\n",
        "    return tf.image.psnr(y_true, y_pred, 1.0)\n",
        "\n",
        "def ssim_loss(y_true, y_pred):\n",
        "    return tf.image.ssim(y_true, y_pred, 1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bFXXIfKWojL"
      },
      "source": [
        "* Functions for loading and reading data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "34zFESWuWs7M"
      },
      "outputs": [],
      "source": [
        "def read_hdf5(file):\n",
        "    with h5py.File(file, 'r') as hf:\n",
        "        data = np.array(hf.get('data'))\n",
        "        labels = np.array(hf.get('label'))\n",
        "   \n",
        "        return data,labels"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare training Data\n",
        "\n",
        "* Define data path and where to store model weights, then Initialize model\n",
        "* Load data and split data and labels."
      ],
      "metadata": {
        "id": "i9CJnsHCnht1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "m2XHL5_IXN5p"
      },
      "outputs": [],
      "source": [
        "# patch_size = '64_64'\n",
        "# dataset_type = ['thoracic', 'piglet', 'head_N012', 'chest_C002', 'abdomen_L058']\n",
        "# train_data_path = ['data/processed/train_{}_{}_dicom_0.h5'.format(patch_size, type_) for type_ in dataset_type]\n",
        "# test_data_path = ['data/processed/test_{}_{}_dicom_0.h5'.format(patch_size, type_) for type_ in dataset_type]\n",
        "\n",
        "def prep_all_train_data(training_files):\n",
        "  training_data, training_labels = [], []\n",
        "\n",
        "  for train_address in training_files:\n",
        "    data,labels = read_hdf5(train_address)\n",
        "    ## divison by 4095 keeps the input output between 0-1\n",
        "    data = (data[:,:,:,None]/4095).astype(np.float32)\n",
        "    labels = (labels[:,:,:,None]/4095).astype(np.float32)\n",
        "    labels_3 = np.concatenate((labels,labels,labels),axis=-1)\n",
        "    training_data.append(data)\n",
        "    training_labels.append(labels_3)\n",
        "\n",
        "  train_data = np.concatenate(training_data, axis=0)\n",
        "  train_labels = np.concatenate(training_labels, axis=0)\n",
        "\n",
        "  return train_data, train_labels\n",
        "\n",
        "training_data, training_labels = prep_all_train_data(train_data_files)\n",
        "# training_data, training_labels = prep_all_train_data(train_data_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fV5BRJ2cQoMF",
        "outputId": "98d5349a-e966-4f38-a43d-1cf1b8adacf2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(136448, 32, 32, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyymP0Z4XViX"
      },
      "source": [
        "### Train the model\n",
        "Main components of the ``train_model`` method:\\\n",
        "* Initialize loss functions and Adam optimizer\n",
        "* Compile model with optimizer, loss functions and metrics\n",
        "* Set up required callbacks for training:\\\n",
        "    * Checkpoint callback: saves model after every epoch (save training if anything were to occur so you can begin from where you left off)\n",
        "    * Clear memory callback: Clears up RAM memory of any unused data so training doesn't crash.\n",
        "* Save model weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vfsZFtjXMUE"
      },
      "outputs": [],
      "source": [
        "def train_model(model, data, labels, weight_address, checkpoint_filepath, loss_weight, numOfEpoch = 60, batch_size = 32):\n",
        "\n",
        "  # Loss functions that require initialization\n",
        "  perceptual = ResNet50V2Model()\n",
        "  mse = MeanSquaredError()\n",
        "\n",
        "  loss = [perceptual.perceptual_loss, mse, dssim_loss]\n",
        "  loss_weights = loss_weight\n",
        "\n",
        "  ADAM=Adam(learning_rate=0.0002, beta_1=0.01, beta_2=0.999)\n",
        "  model.compile(optimizer=ADAM,loss=loss, loss_weights=loss_weights,metrics=[psnr_loss, ssim_loss])\n",
        "\n",
        "  model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "      filepath=checkpoint_filepath,\n",
        "      save_weights_only=True,\n",
        "      monitor='loss',\n",
        "      save_freq='epoch')\n",
        "  \n",
        "  class ClearMemory(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        gc.collect()\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "  # Train\n",
        "  hist_adam = model.fit(x=data,y=[labels,labels,labels],batch_size=batch_size,epochs=numOfEpoch\n",
        "                      ,validation_split=0, verbose=1, shuffle=True, callbacks=[model_checkpoint_callback, ClearMemory()]) # early_stop_callback\n",
        "  model.save_weights(weight_address)\n",
        "\n",
        "  cmd = 'cp {} /gdrive/MyDrive/datasets/'.format(weight_address)\n",
        "  os.system(cmd)\n",
        "\n",
        "\n",
        "# Train model\n",
        "weight_address='model/weights/weights_mdrfa_perceptual40_mse30_dsim30.h5'\n",
        "checkpoint_filepath = '/gdrive/MyDrive/datasets/weights_mdrfa_perceptual40_mse30_dsim30_ckpt.hdf5'\n",
        "model = md_rfa()\n",
        "loss_weights = [40,30,30]\n",
        "\n",
        "train_model(model, training_data, training_labels, weight_address, checkpoint_filepath, loss_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### If required resume training from where it left of."
      ],
      "metadata": {
        "id": "SfvFb1EQGuRm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3az4ivlAtDXS"
      },
      "outputs": [],
      "source": [
        "def resume_train_loop(model, data, labels, weight_path, weight_address, checkpoint_filepath, loss_weight, numOfEpoch = 60, batch_size = 32, current_epoch):\n",
        "\n",
        "  numOfEpoch = numOfEpoch - current_epoch\n",
        "  batch_size=32\n",
        "\n",
        "  perceptual = ResNet50V2Model()\n",
        "  mse = MeanSquaredError()\n",
        "\n",
        "  loss = [perceptual.perceptual_loss, mse, dssim_loss]\n",
        "  loss_weights = loss_weight\n",
        "\n",
        "  ADAM=Adam(learning_rate=0.0002, beta_1=0.01, beta_2=0.999)\n",
        "  model.compile(optimizer=ADAM,loss=loss, loss_weights=loss_weights,metrics=[psnr_loss, ssim_loss])\n",
        "\n",
        "  model.load_weights(weight_path)\n",
        "\n",
        "  model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "      filepath=checkpoint_filepath,\n",
        "      save_weights_only=True,\n",
        "      monitor='loss',\n",
        "      save_freq='epoch')\n",
        "  \n",
        "  class ClearMemory(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        gc.collect()\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "  ###Train\n",
        "  hist_adam = model.fit(x=data,y=[labels,labels,labels],batch_size=batch_size,epochs=numOfEpoch\n",
        "                      ,validation_split=0, verbose=1, shuffle=True, callbacks=[model_checkpoint_callback, ClearMemory()]) # early_stop_callback\n",
        "  model.save_weights(weight_address)\n",
        "\n",
        "  cmd = 'cp {} /gdrive/MyDrive/datasets/'.format(weight_address)\n",
        "  os.system(cmd)\n",
        "\n",
        "# Resume Training if required\n",
        "weight_path = '/content/datasets/weights_md_rfa_50_perceptual40_mse30_dsim30_ckpt.hdf5'\n",
        "weight_address='model/weights/weights_md_rfa_60_perceptual40_mse30_dsim30.h5'\n",
        "checkpoint_filepath = '/gdrive/MyDrive/datasets/weights_md_rfa_50_perceptual40_mse30_dsim30_ckpt.hdf5'\n",
        "model=md_rfa()\n",
        "loss_weights = [40,30,30]\n",
        "last_epoch = 50\n",
        "\n",
        "resume_train_loop(model, training_data, training_labels, weight_path, weight_address, checkpoint_filepath, loss_weights, current_epoch = last_epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test the model\n",
        "\n",
        "* Prepare dataset\n",
        "* Prepare methods for mesuring performance (PSNR and SSIM)\n",
        "* Test model and save results"
      ],
      "metadata": {
        "id": "7d7qXfNZxyhd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Miscellaneous"
      ],
      "metadata": {
        "id": "ssRfEpdeHKH5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByBg4734JGNb"
      },
      "outputs": [],
      "source": [
        "dataset_type = ['thoracic', 'piglet', 'head', 'chest', 'abdomen']\n",
        "def drive_to_local():\n",
        "  cmd = 'cp ./datasets/weights_kevin_unet_perceptual40_mse30_dsim30.h5 ./model/weights/'\n",
        "  os.system(cmd)\n",
        "  # for data_type in dataset_type:\n",
        "  #   cmd = 'cp ./datasets/weights_luella_original_perceptual50_mse20_dsim30.h5 ./model/weights/'\n",
        "  #   os.system(cmd)\n",
        "\n",
        "drive_to_local()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing test dataset and metrics"
      ],
      "metadata": {
        "id": "xHTJFS04HUUw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "XlfN-Hv0LvKm"
      },
      "outputs": [],
      "source": [
        "# patch_size = '64_64'\n",
        "# dataset_type = ['thoracic', 'piglet', 'head_N012', 'chest_C002', 'abdomen_L058']\n",
        "# test_data_path = ['data/processed/test_{}_{}_dicom_0.h5'.format(patch_size, type_) for type_ in dataset_type]\n",
        "def prep_all_testing_data(test_data_files):\n",
        "  testing_data, testing_labels = [], []\n",
        "  for test_address in test_data_files:\n",
        "    data_test,labels_test = read_hdf5(test_address)\n",
        "    data_test = (data_test[:,:,:,None]/4095).astype(np.float32)\n",
        "    labels_test = (labels_test[:,:,:,None]/4095).astype(np.float32)\n",
        "    testing_data.append(data_test)\n",
        "    testing_labels.append(labels_test)\n",
        "\n",
        "  return testing_data, testing_labels\n",
        "\n",
        "testing_data, testing_labels = prep_all_testing_data(test_data_files)\n",
        "# testing_data, testing_labels = prep_all_testing_data(test_data_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing_data[4].shape"
      ],
      "metadata": {
        "id": "OquJO6aq8A40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Metrics used for measuring performance"
      ],
      "metadata": {
        "id": "W4f1gUzkHtrn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "r_36H9gcBlYB"
      },
      "outputs": [],
      "source": [
        "def measure_psnr(test_labels, pred_labels):\n",
        "  diff = test_labels-pred_labels\n",
        "  diff = diff.flatten('C')\n",
        "  rmse = math.sqrt( np.mean(diff ** 2.) )\n",
        "  psnr = 20*math.log10(1.0/rmse)\n",
        "  return psnr\n",
        "\n",
        "def measure_ssim(test_labels, pred_labels):\n",
        "  ssim = 0\n",
        "  for i in range (test_labels.shape[0]):\n",
        "      ssim += compare_ssim(test_labels[i,:,:,0],pred_labels[i,:,:,0],\n",
        "                  data_range=pred_labels[i,:,:,0].max()-pred_labels[i,:,:,0].min())\n",
        "      \n",
        "  ssim = ssim/test_labels.shape[0]\n",
        "  return ssim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the model:\n",
        "\n",
        "* Initialize a dictionary and list for storing both measurements and images\n",
        "* Initialize loss functions and Adam optimizer then recompile model for testing"
      ],
      "metadata": {
        "id": "_wA17xmhKy_e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvSTaFuCPBo_"
      },
      "outputs": [],
      "source": [
        "def test_model(model, data, labels, model_weight_address, dataset_type, loss_weight):\n",
        "  results_dict = {}\n",
        "  pred_results = []\n",
        "  \n",
        "  perceptual = ResNet50V2Model()\n",
        "  mse = MeanSquaredError()\n",
        "\n",
        "  loss = [perceptual.perceptual_loss, mse, dssim_loss]\n",
        "  loss_weights = loss_weight\n",
        "\n",
        "  ADAM=Adam(learning_rate=0.0002, beta_1=0.01, beta_2=0.999)\n",
        "  model.compile(optimizer=ADAM,loss=loss, loss_weights=loss_weights,metrics=[psnr_loss, ssim_loss])\n",
        "\n",
        "  model.load_weights(weight_address)\n",
        "\n",
        "  for i in range(len(dataset_type)):\n",
        "\n",
        "    [labels_pred,labels_pred, labels_pred]= model.predict(data[i],batch_size=8,verbose=1)\n",
        "\n",
        "    psnr = measure_psnr(labels[i], labels_pred)\n",
        "    ssim = measure_ssim(labels[i], labels_pred)\n",
        "\n",
        "    results_dict[dataset_type[i]] = {'psnr':psnr, 'ssim':ssim}\n",
        "    pred_results.append(labels_pred)\n",
        "\n",
        "    labels_test_3 = np.concatenate((labels[i],labels[i],labels[i]),axis=-1)\n",
        "\n",
        "    loss=model.evaluate(x=data[i],y=[labels_test_3,labels_test_3,labels_test_3], batch_size=8,verbose=1)\n",
        "\n",
        "  return results_dict, pred_results\n",
        "\n",
        "# Test model\n",
        "model=md_rfa()\n",
        "loss_weight = [40,30,30]\n",
        "weight_address='/content/datasets/weights_mdrfa_perceptual40_mse30_dsim30.h5'\n",
        "results, pred_results = test_model(model, testing_data, testing_labels, weight_address, dataset_type, loss_weight)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_results[0].shape"
      ],
      "metadata": {
        "id": "naMZR2NQYqMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Viewing results"
      ],
      "metadata": {
        "id": "lPaVj6JyLGQO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Windowing2 Method:\n",
        "* Denormalizes images"
      ],
      "metadata": {
        "id": "D-7rd0ERJz1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def windowing2(image,center,width):\n",
        "    min_bound = center - width/2\n",
        "    max_bound = center + width/2\n",
        "    output = (image-min_bound)/(max_bound-min_bound)\n",
        "    output[output<0]=0\n",
        "    output[output>1]=1\n",
        "    return output"
      ],
      "metadata": {
        "id": "qhRMWpd6pWEM"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Used to create new directories to save results in"
      ],
      "metadata": {
        "id": "eKDMSTcHKLt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dir = ['thoracic', 'piglet', 'head_N012', 'chest_C002', 'abdomen_L058']\n",
        "dir_set = ['test_data', 'test_labels', 'test_results']\n",
        "for dataset in dataset_dir:\n",
        "  os.mkdir(dataset)\n",
        "  for dir in dir_set:\n",
        "    path = '{}/{}'.format(dataset,dir)\n",
        "    os.mkdir(path)"
      ],
      "metadata": {
        "id": "Ci7MiN5N1bKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.utils import array_to_img                                        \n",
        "\n",
        "dataset_dir = ['thoracic', 'piglet', 'head_N012', 'chest_C002', 'abdomen_L058']\n",
        "dir_set = ['test_data', 'test_labels', 'test_results']\n",
        "for i in range(len(pred_results)):\n",
        "  num_images, _, _, _ = pred_results[i].shape\n",
        "  for dir in dir_set:\n",
        "    for j in range(num_images):\n",
        "      if dir == 'test_data':\n",
        "        data = testing_data[i][j,:,:,:]\n",
        "        img = windowing2((data)*4095-1024,40,400)\n",
        "        img = array_to_img(img)\n",
        "        path = '{}/{}/test_img{}.png'.format(dataset_dir[i], dir, j)\n",
        "        img.save(path)\n",
        "      elif dir == 'test_labels':\n",
        "        data = testing_labels[i][j,:,:,:]\n",
        "        img = windowing2((data)*4095-1024,40,400)\n",
        "        img = array_to_img(img)\n",
        "        path = '{}/{}/gt_img{}.png'.format(dataset_dir[i], dir, j)\n",
        "        img.save(path)\n",
        "      if dir == 'test_results':\n",
        "        data = pred_results[i][j,:,:,:]\n",
        "        img = windowing2((data)*4095-1024,40,400)\n",
        "        img = array_to_img(img)\n",
        "        path = '{}/{}/pred_img{}.png'.format(dataset_dir[i], dir, j)\n",
        "        img.save(path)\n"
      ],
      "metadata": {
        "id": "ChxFgiBk5-o7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/abdomen_L058.zip /content/abdomen_L058/\n",
        "!zip -r /content/chest_C002.zip /content/chest_C002/\n",
        "!zip -r /content/head_N012.zip /content/head_N012/\n",
        "!zip -r /content/piglet.zip /content/piglet/\n",
        "!zip -r /content/thoracic.zip /content/thoracic/"
      ],
      "metadata": {
        "id": "Hyo4hoRbA21v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prints the results saved on the Pandas dataframe"
      ],
      "metadata": {
        "id": "5k9nHLjeKWja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "df"
      ],
      "metadata": {
        "id": "gsX1TsAsjoLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(testing_data[1][1,:,:,0], cmap='gray')\n",
        "plt.show()\n",
        "plt.figure()\n",
        "plt.imshow((labels_pred)[1,:,:,0], cmap='gray')\n",
        "plt.show()\n",
        "plt.figure()\n",
        "plt.imshow(testing_labels[1][1,:,:,0], cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print('The PSNR is:', psnr_edge_p)\n",
        "print('The SSIM is:', ssim_edge_p)"
      ],
      "metadata": {
        "id": "cMLRHBmuTmhm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}